---
title: "Analysis"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# An analysis using LiDAR data to detect moose browsing effects, with ground truthing

```{r, message=FALSE}
library(readr)
library(ggplot2)
library(glmmTMB)
library(ggplot2)
library(ggpubr)
library(reshape2)
library(corrgram)
library(arm)
library(lme4)
library(MuMIn)
library(car)
library(pryr) # %<a-%
library(corrplot)
library(latticeExtra)

```

# Get compiled dataset (see compile.R)

```{r}
dat <- read_csv("../data/compiledDataset.csv")
head(dat)
```

# Housekeeping
```{r}
dat$Treatment <- as.factor(dat$Treatment)
levels(dat$Treatment) <- c('Open plot','Exclosure')
```


Calculating AGB after Ã˜kseter et al 2015

```{r}
dat$AGB <- 
   exp(log(38.55)+0.75*log(dat$lasR_D6)+0.63*log(dat$lasR_D9)+1.68*asinh(dat$lasR_Hskew)+0.78*asinh(dat$lasR_H30))

plot(dat$AGB)
```

```{r, warning=F}
tapply(dat$AGB, dat$Treatment, FUN = mean, na.rm=T)
```

# We might need these:
```{r}
dat$canopygrowth <- dat$ninetyfive/dat$YrsSinceExclosure # in m
dat$MgAGBperYearAndHA <- dat$AGB/dat$YrsSinceExclosure
```

```{r}
dat$vci[is.na(dat$vci)] <- 0
```

This is the dataset after removing the two most productive sites (explained below)
```{r}
dat2 <- dat[dat$prod <0.7,]
```



## A quick data check
```{r}
table(dat$Treatment, dat$Clear.cut)
```

```{r}
table(dat$Year.initiated, dat$LiDAR.data.from.year)
```

```{r}
table(dat$plot_density_m2, dat$resolution_m)
```
Something odd there...

```{r}
table(dat$region, dat$Treatment)
```

```{r}
table(dat$LocalityName, dat$Treatment)
```
Looks good.

# Investigating VCI
```{r}
summary(dat$vci)
```
VCI function gives NA when the max point height is <1m (2* bin width set to 0.5). So these are super short statured plots. Its fine to set these to zero, as we have done above.



# Site table
```{r}
sites <- dat[dat$Treatment=="Open plot",]
#write_csv(sites, "../output/sites.csv")
```


# Investiaging other parameters
We have four parameters of interest. 
```{r}
par(mfrow=c(2,2))
boxplot(dat$AGB~dat$Treatment, ylab="Biomass (Mg / ha)")
boxplot(dat$rumple~dat$Treatment, ylab="Rumple Index")
boxplot(dat$ninetyfive~dat$Treatment, ylab="95th percentile (m)")
boxplot(dat$vci~dat$Treatment, ylab="Vertical Complexity Index")
```
```{r}
M<-cor(dat[,c("vci", "rumple", "prod", 
                 "AGB", "ninetyfive",
                 "YrsSinceExclosure")])

corrplot::corrplot(M, method="number", type="lower")
```
We have to measures of strucural complexity, rumple and VCI. They are correlated, but rumple is strongly correlated to biomass, so we will use VCI.

```{r}
pairs(dat[,c("vci", "rumple", "prod", 
                 "AGB", "ninetyfive",
                 "YrsSinceExclosure")])
```

# Canopy height
We use the 95th percentil instead of Hmax because it's less sensitive to outliers and variation in point density.
```{r}
plot(dat$ninetyfive)
```

## Canopy growth per year
```{r}
ggplot(data = dat, aes(x = YrsSinceExclosure, y = ninetyfive))+
  geom_point(aes(colour= Treatment, shape=region))+
   geom_smooth(aes(colour= Treatment),
               method = "loess", se=F)+
  labs(y='Canopy height', x='Years since exclosure')+
  theme_bw()+
  scale_color_manual(values = c("gray0", "gray60"))+
  labs(colour="Treatment", shape="Region")+
  theme(text = element_text(size = 20))+
  theme(legend.position = 'right',
                             legend.justification = c("left", "top"),
                             legend.box.just = "left",
                             #legend.margin = margin(5, 5, 5, 5),
                             legend.text = element_text(size=12))
```
Loess gave some warnings here, but still, this plot shows that it's quite linear.


One of the first things to decide on is what to do with productivity, as there are two outliers:
```{r}
plot(dat$prod, ylab="Productivity")
```
```{r}
dat[dat$prod>0.6,c("LocalityName", "region", "prod")]
```
These are two sites in Hedmark that probably really are very productive, although there could have been serious sampling error due to chance. But they are legitimate, and we should be careful not to drop them too willingly. 

After careful sensitivity analysis, I decided to drop these two locations in dat2. Scripts are moved to the end of the file

## modelling
```{r}
dat2$prod2 <- dat2$prod^2
mod_sens1 <- glmmTMB(ninetyfive ~ 
             Treatment * prod + I(prod^2)
             + YrsSinceExclosure+ 
               YrsSinceExclosure:Treatment + (1|region) + (1|LocalityName),
  data = dat2,  REML=F, family = gaussian)

mod_sens2 <- glmmTMB(ninetyfive ~ Treatment * prod + prod2
        + YrsSinceExclosure+ 
          YrsSinceExclosure:Treatment +  (1|LocalityName),
  data = dat2, REML=F, family = gaussian)
AIC(mod_sens1, mod_sens2)
```
Regions explains nothing, so I'm removing it

```{r}
summary(mod_sens2)
```

glmmTMB is not supported by arm::standardise, 
```{r}
dat2$prod_s <- scale(dat2$prod)
dat2$prod2_s <- scale(dat2$prod2)
dat2$YrsSinceExclosure_s <- scale(dat2$YrsSinceExclosure)
dat2$Treatment_c <- ifelse(dat2$Treatment == "Open plot", -0.5, 0.5)
dat2$ninetyfive_s <- scale(dat2$ninetyfive)[,1]
summary(dat2$ninetyfive_s)
sd(dat2$ninetyfive_s)

mod_sens2_s <- glmmTMB(ninetyfive_s ~ Treatment_c * prod_s + prod2_s
                     + YrsSinceExclosure_s+ YrsSinceExclosure_s:Treatment+ 
                    (1|LocalityName), REML=F,
                       data = dat2)


summary(mod_sens2_s)
```

Scaling predictors make it easier to compare slopes, but unstandardised models are much easier to work with for making predictions ect.
```{r}
#stdz_model <- standardize(mod_sens2, standardize.y = FALSE, unchanged="Treatment")
#summary(stdz_model)
```


Then we find all possible model configurations 
```{r}
options(na.action = "na.fail")
#cg_cand <- dredge(mod_sens2_s, beta="none", rank = "AICc")
#write_rds(cg_cand, "../data/cg_cand.RData")
cg_cand <- read_rds("../data/cg_cand.RData")
```

Lets compare this to the un.standardised model
```{r}
#uns <- dredge(mod_sens2, beta="none", rank = "AICc")
#write_rds(uns, "../data/uns.RData")
uns <- read_rds("../data/uns.RData")
```

create confidence set with model less than 2 AICc units
```{r}
(cg_cand2 <- subset(cg_cand, delta <2))
```
We exclude models with quadratic terms when the main effect is not in the model, if there are such.
```{r}
cg_cand2 <- cg_cand2[-3,]
```

Lets compare to the unstandardised model
```{r}
(uns2 <- subset(uns, delta <2))
```
removing model 3
```{r}
(uns2 <- uns2[-3,])
```
The model weights are exactly the same.

Lets export this as a table for the supplementary
```{r, eval=F}
temp <- as.data.frame(uns2)
names(temp) <- c("Intercept",
                      "Productivity (P)",
                      "Productivity squared",
                 "Herbivore Exclusion (HE)",
                      "Experimental duration (ED)",
                      "HE x P",
                      "HE x ED",
                      "df",
                      "log likelihood",
                      "AICc",
                      "delta AICc",
                      "weight"
                      )
temp[is.na(temp)] <- 0
#write.csv(temp, "../output/95thModelSet_unstandardized.csv", row.names = F)
```


Average across these three models
```{r}
MA.ests<-model.avg(cg_cand2, revised.var = TRUE, fit=F)
MA.ests_uns <-model.avg(uns2, revised.var = TRUE, fit=T) # used for predictions
summary(MA.ests)
```

```{r}
summary(MA.ests_uns)
```
No they're not the same. Not sure why, but part of the reason must be that treatment has been centred.

Get parameter weights
```{r}
importance(MA.ests)
```
 
prod and prod2 and highly collinear, and more so when using prod2 compared to I(prod^2)
 
We want to get at the values to plot them. The intercept dont make sense in averaged models, so remove intercept from table
```{r}
(macdf <- data.frame(summary(MA.ests)$coefmat.subset[-1,]))
```

get the weights and add them to the same table
```{r}
impdf<-data.frame(importance(MA.ests))
impdf <- as.numeric(impdf[,1])
macdf$importance.MA.ests.<-impdf # this works cause thyr ordered in the same way
macdf
```

Then we also need the 95 CIs
```{r}
cis <- confint(MA.ests)
cis <- cis[-1,]
cis <- as.data.frame(cis)
macdf$low <- cis[,1]
macdf$high <- cis[,2]
macdf
```

Lets order them after effect size
```{r}
macdf3<-macdf[order(macdf$Estimate),]
```

Fix names
```{r}
Row.names<-c('Productivity squared',
             'Productivity',
             'Experimental duration (ED)',
             'HE x ED',
             'Herbivore Exclusion (HE)'
                    )
macdf3 <- cbind(Row.names, macdf3)
macdf3
```

Then lets make the figure
First, adding empty row
```{r}
macdf4 <- macdf3[-(1:nrow(macdf3)),]
macdf4[1,] <- c(NA, NA, NA, NA, NA, NA, NA, NA, NA) 
macdf4[2,] <- c(NA, 100, NA, NA, NA, NA, NA, NA, NA) 

macdf3 <- rbind(macdf3, macdf4)
macdf3$Row.names <- as.character(macdf3$Row.names)
macdf3$Row.names[6] <- "Canopy height:"
```

```{r}
canopyAvg %<a-% {
  
par(oma=c(1,10,1,1))
par(mfrow=c(1,2))
par(mar=c(5,0,1,1))
par(xpd=T)

barplot(macdf3$importance.MA.ests.,
        beside=T,horiz=T,
        names.arg=macdf3$Row.names,
        las=1,
        xlab='Importance',
        cex.axis=0.8,
        cex.names=0.8,
        cex.lab=0.8,
        col=c(0,0,0,2,2, 0))
par(mar=c(5,1,1,1))
b1 <- barplot(macdf3[,2],
            horiz=T,
            col=F,
            border=F,
            xlim=c(-1.2,1.2),
            las=1,
            xlab='Standardised, model\naveraged coefficients',
            cex.axis=0.8,
            cex.lab=0.8)
points(macdf3[,2], #est
       b1,
       pch=16,
       col=c(1,1,1,2,2, 1))
arrows(macdf3[,9], 
       b1,                         
       macdf3[,8], 
       b1,
       code=3,
       angle=90,
       length=0.05,
       col=c(1,1,1,2,2, 1))
par(xpd=F)
abline(v=0,lty=2)
}
canopyAvg
```


This figure can be exported but I'll wait and do it later
```{r, eval=F}
tiff("/home/anders/Documents/lidar ms/avgCanopyMod.tiff", height = 5, width=7, units="in", res=600)
canopyAvg
dev.off()
```

## Dotplot
```{r}
cg_viol <- 
   ggplot(data = dat2, aes(x = Treatment, y = canopygrowth))+
  geom_violin(fill = "grey", alpha=0.7)+
  theme_bw()+
  theme(text = element_text(size = 12))+
  labs(y=expression(paste('Canopy height growth (m year'^'-1', ')')), x='')+
  stat_summary(fun.y=mean, geom="point", shape=23, size=2)+
  xlab("")


ch_viol <- 
   ggplot(data = dat2, aes(x = Treatment, y = ninetyfive, fill=Treatment))+
 # geom_violin(fill = "grey", alpha=0.7)+
  theme_bw()+
  theme(text = element_text(size = 12))+
  labs(y='Canopy height (m)')+
  xlab("")+
  geom_dotplot(binaxis='y', stackdir='center', 
               stroke=2)+
  scale_fill_manual(values = c("grey40", "white"))+
  guides(fill=F)+
  stat_summary(fun.y=mean, geom="point", shape=23, size=4, fill="black")

viol <- ggarrange(ch_viol, cg_viol,
                    labels = c("A", "B"),
                    ncol = 2, nrow = 1)

viol
```

```{r, eval=F}
#tiff("/home/anders/Documents/lidar ms/violinPlot.tiff", height = 5, width=7, units="in", res=600)
viol
#dev.off()
```


Then we need to plot canopy height against experimental duration. There is a predict function in MuMIn.

```{r}
all.vars(formula(MA.ests_uns))
```

```{r}            
newd <- dat2
newd$YrsSinceExclosure <- rep(seq(from = min(dat2$YrsSinceExclosure), 
                             to=max(dat2$YrsSinceExclosure), length.out = 43), 2)
newd$prod <- rep(mean(dat2$prod), nrow(newd))
newd$prod2 <- rep(mean(dat2$prod2), nrow(newd))
newd$LocalityName <- rep(NA, 86)
pred <- predict(MA.ests_uns,
                            se.fit = TRUE,
                            full=FALSE,
                            re.form=~0, # same as leaving out LocalityName
                newdata=newd
                )

pred2 <- data.frame(Treatment = newd$Treatment,
                    YrsSinceExclosure      = newd$YrsSinceExclosure,
                    pred      = pred$fit,
                    se        = pred$se.fit)
  
(Canopy_line <-    
    ggplot()+
  geom_point(data = dat2, 
             aes(x = YrsSinceExclosure, 
                 y = ninetyfive, 
                 fill=Treatment),
             size=4, shape = 21, stroke=2, alpha=0.8)+
  scale_fill_manual(values = c("white", "grey40"))+
#  , 
#                    breaks=c("Exclosure", "Open plot"),
#                    labels=c("Exclosure", "Open plot"))+
  
  scale_linetype_manual("", values=c(6,1),
                       breaks=c("Exclosure", "Open plot"),
                    labels=c("Exclosure", "Open plot"))+
    
  geom_line(data=pred2, 
            aes(x = YrsSinceExclosure, y=pred, linetype = Treatment),
            lwd=1.5)+
    
  geom_ribbon(data=pred2, aes(x = YrsSinceExclosure, 
                 ymin=pred-se, 
                 ymax=pred+se, 
                 group = Treatment),
                 alpha=0.2,
                 linetype="blank")+
        theme_bw()+
  theme(legend.justification=c(1,0), 
        legend.position=c(1,0),
        legend.background = element_blank(),
        legend.text = element_text(size=12),
        text = element_text(size = 12))+
guides(linetype=F, fill=F)+
  
  labs(y="Canopy height (m)")+
  xlab("Experimental duration"))
```




# VCI

```{r}

(vci_line <- 
   ggplot(data = dat2, aes(x = prod, y = vci, shape=Treatment))+
  geom_point(size=3, alpha=0.8)+
  scale_shape_manual(values = c(16, 1))+
  geom_smooth(method="lm", aes(linetype=Treatment), colour="black")+
  theme_bw()+
  theme(text = element_text(size = 12))+
  labs(y="VCI")+
  xlab("Productivity"))
```

```{r}
(vci_line2 <- 
   ggplot(data = dat2, aes(x = YrsSinceExclosure, y = vci, shape=Treatment))+
  geom_point(size=3, alpha=0.8)+
  scale_shape_manual(values = c(16, 1))+
  geom_smooth(method="lm", aes(linetype=Treatment), colour="black")+
  theme_bw()+
  theme(text = element_text(size = 12))+
  labs(y="VCI")+
  xlab("YrsSinceExclosure"))
```

```{r}
dat2$vci_s <- scale(dat2$vci)[,1]

mod_vci <- glmmTMB(vci ~ Treatment * prod + YrsSinceExclosure + YrsSinceExclosure:Treatment+ prod2 +  (1|LocalityName),
  data = dat2, REML=F, family = gaussian)

mod_vci_s <- glmmTMB(vci_s ~ Treatment_c * prod_s + YrsSinceExclosure_s + YrsSinceExclosure_s:Treatment_c+ prod2_s +  (1|LocalityName),
  data = dat2, REML=F,  family = gaussian)

summary(mod_vci)
```

```{r}
#dmod_vci <- dredge(mod_vci, beta="none", rank = "AICc")
#write_rds(dmod_vci, "../data/dmod_vci.RData")
dmod_vci <- read_rds("../data/dmod_vci.RData")
#dmod_vci_s <- dredge(mod_vci_s, beta="none", rank = "AICc")
#write_rds(dmod_vci_s, "../data/dmod_vci_s.RData")
dmod_vci_s <- read_rds("../data/dmod_vci_s.RData")
```

```{r}
(dmod_vci2 <- subset(dmod_vci, delta <2))
```

```{r}
(dmod_vci_s2 <- subset(dmod_vci_s, delta <2))
```

```{r}
importance(dmod_vci2)
```

Lets export this as a table for the supplementary
```{r}
temp <- as.data.frame(dmod_vci2)
temp <- temp[,-2]
names(temp) <- c("Intercept",
                      "Productivity (P)",
                      "Productivity squared",
                 "Herbivore Exclusion (HE)",
                      "Experimental duration (ED)",
                      "HE x P",
                      "HE x ED",
                      "df",
                      "log likelihood",
                      "AICc",
                      "delta AICc",
                      "weight"
                      )
temp[is.na(temp)] <- 0
#write.csv(temp, "../output/VCIModelSet_unstandardized.csv", row.names = F)
```


Average across these three models
```{r}
VCIavg     <-model.avg(dmod_vci_s2, revised.var = TRUE, fit=F)
VCIavg_uns <-model.avg(dmod_vci2, revised.var = TRUE, fit=T) # used for predictions
summary(VCIavg_uns)
```
Lets add the standardized stuff to the canopy height figure


```{r}
(figdat <- data.frame(summary(VCIavg)$coefmat.subset[-1,]))
```

get the weights and add them to the same table
```{r}
VCIimpdf<-data.frame(importance(VCIavg))
VCIimpdf[c(4,1,2,3,5),]

VCIimpdf <- as.numeric(VCIimpdf[,1])
figdat$importance.MA.ests.<-VCIimpdf[c(4,1,2,3,5)] 
figdat
```

Then we also need the 95 CIs
```{r}
cis <- confint(VCIavg)
cis <- cis[-1,]
cis <- as.data.frame(cis)
figdat$low <- cis[,1]
figdat$high <- cis[,2]
figdat
```

Lets order them after effect size
```{r}
figdat<-figdat[order(figdat$Estimate),]
```

Fix names
```{r}
Row.names<-c('Productivity squared',
             'HE x ED',
             'Experimental duration (ED)',
             'Herbivore Exclusion (HE)',
             'Productivity'
                    )
figdat <- cbind(Row.names, figdat)
figdat
```

Then lets make the figure
First, adding empty row
```{r}
b <- macdf3
colnames(macdf3)
figdat2 <- figdat[-(1:nrow(figdat)),]
figdat2[1,] <- c(NA, 100, NA, NA, NA, NA, NA, NA, NA) 
figdat3 <- rbind(figdat, figdat2)
figdat3$Row.names <- as.character(figdat3$Row.names)
figdat3$Row.names[6] <- "VCI:"
```

Combine:
```{r}
figdat4 <- rbind(macdf3, figdat3)
```

```{r}
Avg %<a-% {
  
par(oma=c(1,10,1,1))
par(mfrow=c(1,2))
par(mar=c(5,0,1,1))
par(xpd=T)

barplot(figdat4$importance.MA.ests.,
        beside=T,horiz=T,
        names.arg=figdat4$Row.names,
        las=1,
        xlab='Importance',
        cex.axis=0.8,
        cex.names=0.8,
        cex.lab=0.8,
        col=c(0,0,0,2,2,0,0,0,2,0,2,0,0))
par(mar=c(5,1,1,1))
b1 <- barplot(figdat4[,2],
            horiz=T,
            col=F,
            border=F,
            xlim=c(-1.2,1.5),
            las=1,
            xlab='Standardised, model\naveraged coefficients',
            cex.axis=0.8,
            cex.lab=0.8)
points(figdat4[,2], #est
       b1,
       pch=16,
       col=c(1,1,1,2,2,1,1,1,2,1,2,1,1))
arrows(figdat4[,9], 
       b1,                         
       figdat4[,8], 
       b1,
       code=3,
       angle=90,
       length=0.05,
       lwd=3,
       col=c(1,1,1,2,2,1,1,1,2,1,2,1,1))
par(xpd=F)
abline(v=0,lty=2)
}
Avg
```

```{r, eval=F}
tiff("/home/anders/Documents/lidar ms/modAveragedEst.tiff", 
     height = 8, width=8, units="in", res=600)
Avg
dev.off()
```

##Plot VCI against productivity
```{r}
all.vars(formula(VCIavg_uns))
```

```{r}
newd <- dat2

newd$YrsSinceExclosure <- 
    rep(mean(dat2$YrsSinceExclosure),length.out = 86)

newd$prod <- 
     rep(seq(from = min(dat2$prod), 
      to=max(dat2$prod), length.out = 43), 2)

newd$prod2 <- newd$prod*newd$prod

newd$LocalityName <- rep(NA, 86)

pred <- predict(VCIavg_uns,
                            se.fit = TRUE,
                            full=FALSE,
                            re.form=~0, # same as leaving out LocalityName
                newdata=newd
                )

pred2 <- data.frame(Treatment              = newd$Treatment,
                    YrsSinceExclosure      = newd$YrsSinceExclosure,
                    prod                   = newd$prod,
                    prod2                  = newd$prod2,
                    pred                   = pred$fit,
                    se                     = pred$se.fit)


  (vci_line <-    ggplot()+
     geom_point(data = dat2, 
             aes(x = prod, y = vci, fill=Treatment),
             size=4, alpha=0.8, shape=21, stroke=2)+
      scale_fill_manual("",values = c("white", "grey20") ,
                    breaks=c("Exclosure", "Open plot"),
                    labels=c("Exclosure", "Open plot"))+
  geom_line(data=pred2, 
            aes(x = prod, y=pred, linetype = Treatment),
            lwd=1.5)+
 
 scale_linetype_manual("", values=c(6,1),
                       breaks=c("Exclosure", "Open plot"),
                    labels=c("Exclosure", "Open plot"))+
  geom_ribbon(data=pred2, aes(x = prod, 
                 ymin=pred-se, 
                 ymax=pred+se, 
                 group = Treatment),
                 alpha=0.2,
                 linetype="blank")+
        theme_bw()+
  theme(legend.justification=c(1,0), 
        legend.position=c(1,0),
        legend.background = element_blank(),
        legend.text = element_text(size=12),
        text = element_text(size = 12))+
  labs(y="VCI")+
  xlab("Productivity"))
```





# Biomass 
## Violin/dotplot plot
```{r}
(AGBviol <- ggplot(data =dat2, aes(x=Treatment, y=AGB,  fill=Treatment))+
  #geom_violin(fill = "grey", alpha=0.7)+
  theme_bw()+
  theme(text = element_text(size = 12))+
  labs(y=expression(paste('Above ground biomass (Mg ha'^'-1', ')')), x='')+
  xlab("")+
  geom_dotplot(binaxis='y', stackdir='center', 
               stroke=2, binwidth = 1)+
   scale_fill_manual(values = c("white", "grey40"))+
  stat_summary(fun.y=mean, geom="point", 
               shape=23, size=4, fill="black")+
  guides(fill = F))
```

Plotting treatment difference could be done like this
```{r}
library(reshape2)
datB <- dcast(data=dat2, value.var="MgAGBperYearAndHA", LocalityName+prod+YrsSinceExclosure~Treatment)
datB$diff <- datB$Exclosure - datB$`Open plot`
(agb_line <- 
   ggplot(data = dat2, aes(x = prod, y = MgAGBperYearAndHA, colour=Treatment))+
  geom_point()+
  theme_bw()+
  theme(text = element_text(size = 12))+
  labs(y=expression(paste('Annual biomass increment (Mg ha'^'-1', ')')), x='')+
  stat_summary(fun.y=mean, geom="point", shape=23, size=2)+
  xlab("Productivity"))
(agb_line2 <- 
   ggplot(data = datB, aes(x = prod, y = diff))+
  geom_point(fill="grey", colour="black", size=3, shape=21, stroke=1.2, alpha=.7)+
  theme_bw()+
  theme(text = element_text(size = 12))+
  #labs(y=expression(atop("Exclosure - Open plot", 
  #            paste('annual biomass increment (Mg ha'^'-1', ')')), x=''))+
  labs(y=expression(
              paste('AGB (Mg ha'^'-1', ') (Excl.-Open plot)')))+
  xlab("Productivity"))

#tiff("/home/anders/Documents/lidar ms/AGB.tiff", height = 4, width=4, units="in", res=600)
#agb_line2
#dev.off()
```

##Heatmap with smotting
```{r}
devtools::source_gist('306e4b7e69c87b1826db')

heat <- 
levelplot(diff ~ YrsSinceExclosure * prod, datB, 
          panel = panel.levelplot.points, cex = 1.2, col="black",
          jitter.x = TRUE,
          xlab="Experimental duration (years)",
          ylab="Productivity",
          col.regions=heat.colors(100, rev = T),
          ylab.right = expression(
              paste('AGB (Mg ha'^'-1', ') (Excl.-Open plot)')),
          par.settings = 
            list(layout.widths = list(axis.key.padding = 0,
                                            ylab.right = 2))
    ) + 
    layer_(panel.2dsmoother(..., n = 200))
#tiff("/home/anders/Documents/lidar ms/AGBheatmap.tiff", height = 4, width=5, units="in", res=600)
diverge0(heat, ramp='RdBu')
#dev.off()
```
## Modelling
```{r}
dat2$AGB_s <- scale(dat2$AGB)[,1]

mod_agb <- glmmTMB(AGB ~ Treatment * prod + YrsSinceExclosure + YrsSinceExclosure:Treatment+ prod2 +  (1|LocalityName),
  data = dat2, REML=F, family = gaussian)
# Removing prod2 after first seing that it is not important. I had to do this because it overfitted the dta and crashed the dredge function.
mod_agb <- glmmTMB(AGB ~ Treatment * prod + YrsSinceExclosure + YrsSinceExclosure:Treatment +  (1|LocalityName),
  data = dat2, REML=F, family = gaussian)

mod_agb_s <- glmmTMB(AGB_s ~ Treatment_c * prod_s + YrsSinceExclosure_s + YrsSinceExclosure_s:Treatment_c+ prod2_s +  (1|LocalityName),
  data = dat2, REML=F,  family = gaussian)

summary(mod_agb)
```

```{r}
#dmod_agb <- dredge(mod_agb, beta="none", rank = "AICc")
#write_rds(dmod_agb, "../data/dmod_agb.RData")
dmod_agb <- read_rds("../data/dmod_agb.RData")
#dmod_agb_s <- dredge(mod_agb_s, beta="none", rank = "AICc")
#write_rds(dmod_agb_s, "../data/dmod_agb_s.RData")
dmod_agb_s <- read_rds("../data/dmod_agb_s.RData")
```

```{r}
dmod_agb2 <- subset(dmod_agb, delta <2)
(dmod_agb_s2 <- subset(dmod_agb_s, delta <2))
```
Just two models




```{r}
importance(dmod_agb_s2)
```

Lets export this as a table for the supplementary
```{r}
temp <- as.data.frame(dmod_agb2)
temp <- temp[,-2]
names(temp) <- c("Intercept",
                      "Productivity (P)",
                      
                 "Herbivore Exclusion (HE)",
                      "Experimental duration (ED)",
                      "HE x P",
                      "HE x ED",
                      "df",
                      "log likelihood",
                      "AICc",
                      "delta AICc",
                      "weight"
                      )
temp <- temp[-3,]
#write.csv(temp, "../output/AGBModelSet_unstandardized.csv", row.names = F)
```


### Average
Average across these three models
```{r}
AGBavg     <- model.avg(dmod_agb_s2, revised.var = TRUE, fit=F)
AGBavg_uns <- model.avg(dmod_agb2, revised.var = TRUE, fit=T) # used for predictions
summary(AGBavg_uns)
```
The treatment effect increases with time

Lets add the standardized stuff to the canopy height figure
```{r}
(figdat <- data.frame(summary(AGBavg)$coefmat.subset[-1,]))
```

get the weights and add them to the same table
```{r}
AGBimpdf<-data.frame(importance(AGBavg))
AGBimpdf[c(1,2,3,5,4),]

AGBimpdf <- as.numeric(AGBimpdf[,1])
figdat$importance.MA.ests.<-AGBimpdf[c(1,2,3,5,4)]
figdat
```

Then we also need the 95 CIs
```{r}
cis <- confint(AGBavg)
cis <- cis[-1,]
cis <- as.data.frame(cis)
figdat$low <- cis[,1]
figdat$high <- cis[,2]
figdat
```

Lets order them after effect size
```{r}
figdat<-figdat[order(figdat$Estimate),]
```

Fix names
```{r}
Row.names<-c('Experimental duration (ED)',
             'P x HE',
             'Productivity (P)',
             'HE x ED',
             'Herbivore Exclusion (HE)')
figdat <- cbind(Row.names, figdat)
figdat
```

Then lets make the figure
First, adding empty row
```{r}
# add to figdat4
figdat2 <- figdat[-(1:nrow(figdat)),]
figdat2[1,] <- c(NA, 100, NA, NA, NA, NA, NA, NA, NA) 
figdat3 <- rbind(figdat, figdat2)
figdat3$Row.names <- as.character(figdat3$Row.names)
figdat3$Row.names[6] <- "AGB:"
```

Combine:
```{r}

figdat5 <- rbind(figdat4, figdat3)
```

```{r}
rownames(figdat5) <-  1:19
figdat5 <- rbind(figdat5[1:13,], figdat5[7,], figdat5[14:19,])
figdat5$Row.names[figdat5$Row.names=="Herbivore Exclusion (HE)"] <- 
  "Ungulate exclusion (UE)"
figdat5$Row.names[figdat5$Row.names=="P x HE"] <- "UE x P"
figdat5$Row.names[11] <- "Ungulate exclusion"
figdat5$Row.names[10] <- "Experimental duration"
figdat5$Row.names[5] <- "Ungulate exclusion"
figdat5$Row.names[3] <- "Experimental duration"
figdat5$Row.names[4] <- "UE x ED"
figdat5$Row.names[9] <- "UE x ED"
figdat5$Row.names[18] <- "UE x ED"
```

```{r}
Avg %<a-% {
  
par(oma=c(1,10,1,1))
par(mfrow=c(1,2))
par(mar=c(5,0,1,1))
par(xpd=T)

barplot(figdat5$importance.MA.ests.,
        beside=T,horiz=T,
        names.arg=figdat5$Row.names,
        las=1,
        xlab='Importance',
        cex.axis=0.8,
        cex.names=0.8,
        cex.lab=0.8,
        col=c(0,0,0,2,2,
              0,0,
              0,2,0,2,0,
              0,0,
              0,2,0,2,2,
              0))
par(mar=c(5,1,1,1))
b1 <- barplot(figdat5[,2],
            horiz=T,
            col=F,
            border=F,
            xlim=c(-1.2,1.5),
            las=1,
            xlab='Standardised, model\naveraged coefficients',
            cex.axis=0.8,
            cex.lab=0.8)
points(figdat5[,2], #est
       b1,
       pch=16,
       col=c(1,1,1,2,2,
             1,1,
             1,2,1,2,1,
             1,1,
             1,2,1,2,2,
             1))
arrows(figdat5[,9], 
       b1,                         
       figdat5[,8], 
       b1,
       code=3,
       angle=90,
       length=0.05,
       lwd=3,
       col=c(1,1,1,2,2,
             1,1,
             1,2,1,2,1,
             1,1,
             1,2,1,2,2,
             1))
par(xpd=F)
abline(v=0,lty=2)
}
Avg
```

```{r, eval=F}
tiff("/home/anders/Documents/lidar ms/modAveragedEst.tiff", 
     height = 8, width=8, units="in", res=600)
Avg
dev.off()
```



```{r}
(allPlots <- ggarrange(Canopy_line, ch_viol,AGBviol, vci_line,
                    labels = c("A)", "B)", "C)", "D)"),
                    ncol = 2, nrow = 2))
```

# 4 plots
```{r, eval =F}
tiff("/home/anders/Documents/lidar ms/Figures/4 fourPlots.tiff", 
     height = 12, width=12, units="in", res=600)

allPlots

dev.off()
```



